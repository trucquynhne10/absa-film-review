{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igJMZSLWYCV6",
        "outputId": "b9a71e37-37d6-434b-e1a0-a47421491c9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x-Zmd0MYAkV",
        "outputId": "09eaf727-4f4a-42d6-c4f2-073d1893a398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ABSA-MLQ/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5AkIrmdYD_B",
        "outputId": "3b84dda0-8847-4322-aa45-6fc428412025"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (4.47.1)\n",
            "Collecting underthesea (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2))\n",
            "  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting regrex (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 3))\n",
            "  Downloading regrex-1.3.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 4)) (6.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 9)) (2.2.2)\n",
            "Collecting emoji (from -r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 10))\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2))\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (1.6.0)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2))\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting colorama (from regrex->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 3))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from regrex->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 9)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 9)) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea->-r /content/drive/MyDrive/ABSA-MLQ/requirements.txt (line 2)) (3.5.0)\n",
            "Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: regrex\n",
            "  Building wheel for regrex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regrex: filename=regrex-1.3-py3-none-any.whl size=4664 sha256=7c26a5100f51d29349d78c9d0dd2ccd693d2ada038fef3bbe58933f44a96e1e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/41/5e/5cf175a511c5324711c0f3ce6acab685138057efc08137dab6\n",
            "Successfully built regrex\n",
            "Installing collected packages: underthesea-core, python-crfsuite, emoji, colorama, underthesea, regrex\n",
            "Successfully installed colorama-0.4.6 emoji-2.14.0 python-crfsuite-0.9.11 regrex-1.3 underthesea-6.8.4 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CisUQtzTYGmE",
        "outputId": "c5bcf6f9-7f4f-44f2-ba60-7a270927336a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.17.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.17.1\n",
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow-cpu\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "Successfully installed tensorboard-2.18.0 tensorflow-cpu-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch-xla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpBcaEAZYInB",
        "outputId": "b95375be-aaae-455d-b68c-e723020d7a55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-xla as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 Trainer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvbGDcajYPcy",
        "outputId": "11a9a54b-ea41-44ce-dda1-2d47ed53be84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Loading config {'aspect': ['character', 'content', 'scene', 'sound'], 'labels': ['x', 'o', 'n', 'p'], 'pretrained': 'vinai/phobert-base-v2', 'use_lstm': True, 'num_layers_lstm': 2, 'word_embedding_dim': 512, 'num_embeddings': 256, 'batch_size': 32, 'num_workers': 2, 'num_epochs': 15, 'train_file': 'dataset/train_processed.csv', 'val_file': 'dataset/dev_processed.csv', 'test_file': 'dataset/test_processed.csv', 'freeze_embedder': False, 'acd_warmup': 15, 'acd_only': False, 'acsc_only': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'acd_loss_weight': 1.0, 'acsc_loss_weight': 1.0, 'saved_model': 'log/model_absa.bin', 'model_save_path': 'log/model_absa.bin', 'device': device(type='cuda')}\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/dataset.py:42: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  y = label_encoder_df(data[label_cols].applymap(lambda x: x.lower() if pd.notnull(x) else x)).values.tolist()\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/utils.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return df.replace({'x': 0,\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/dataset.py:42: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  y = label_encoder_df(data[label_cols].applymap(lambda x: x.lower() if pd.notnull(x) else x)).values.tolist()\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/utils.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return df.replace({'x': 0,\n",
            "2025-01-05 09:01:16.666147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/model_utils.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path)\n",
            "### Loading pretrained model from log/model_absa.bin\n",
            "loaded layer: ['log_vars', 'embedding_layer_fc.weight', 'embedding_layer_fc.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l1', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'embedding_layer_aspect_attentions.0.W.weight', 'embedding_layer_aspect_attentions.0.W.bias', 'embedding_layer_aspect_attentions.0.uw.weight', 'embedding_layer_aspect_attentions.1.W.weight', 'embedding_layer_aspect_attentions.1.W.bias', 'embedding_layer_aspect_attentions.1.uw.weight', 'embedding_layer_aspect_attentions.2.W.weight', 'embedding_layer_aspect_attentions.2.W.bias', 'embedding_layer_aspect_attentions.2.uw.weight', 'embedding_layer_aspect_attentions.3.W.weight', 'embedding_layer_aspect_attentions.3.W.bias', 'embedding_layer_aspect_attentions.3.uw.weight', 'category_fcs.0.weight', 'category_fcs.0.bias', 'category_fcs.1.weight', 'category_fcs.1.bias', 'category_fcs.2.weight', 'category_fcs.2.bias', 'category_fcs.3.weight', 'category_fcs.3.bias', 'sentiment_fcs.0.0.weight', 'sentiment_fcs.0.0.bias', 'sentiment_fcs.0.2.weight', 'sentiment_fcs.0.2.bias', 'sentiment_fcs.1.0.weight', 'sentiment_fcs.1.0.bias', 'sentiment_fcs.1.2.weight', 'sentiment_fcs.1.2.bias', 'sentiment_fcs.2.0.weight', 'sentiment_fcs.2.0.bias', 'sentiment_fcs.2.2.weight', 'sentiment_fcs.2.2.bias', 'sentiment_fcs.3.0.weight', 'sentiment_fcs.3.0.bias', 'sentiment_fcs.3.2.weight', 'sentiment_fcs.3.2.bias']\n",
            "non-loaded layer: ['embedder.phobert.embeddings.word_embeddings.weight', 'embedder.phobert.embeddings.position_embeddings.weight', 'embedder.phobert.embeddings.token_type_embeddings.weight', 'embedder.phobert.embeddings.LayerNorm.weight', 'embedder.phobert.embeddings.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.attention.self.query.weight', 'embedder.phobert.encoder.layer.0.attention.self.query.bias', 'embedder.phobert.encoder.layer.0.attention.self.key.weight', 'embedder.phobert.encoder.layer.0.attention.self.key.bias', 'embedder.phobert.encoder.layer.0.attention.self.value.weight', 'embedder.phobert.encoder.layer.0.attention.self.value.bias', 'embedder.phobert.encoder.layer.0.attention.output.dense.weight', 'embedder.phobert.encoder.layer.0.attention.output.dense.bias', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.intermediate.dense.weight', 'embedder.phobert.encoder.layer.0.intermediate.dense.bias', 'embedder.phobert.encoder.layer.0.output.dense.weight', 'embedder.phobert.encoder.layer.0.output.dense.bias', 'embedder.phobert.encoder.layer.0.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.attention.self.query.weight', 'embedder.phobert.encoder.layer.1.attention.self.query.bias', 'embedder.phobert.encoder.layer.1.attention.self.key.weight', 'embedder.phobert.encoder.layer.1.attention.self.key.bias', 'embedder.phobert.encoder.layer.1.attention.self.value.weight', 'embedder.phobert.encoder.layer.1.attention.self.value.bias', 'embedder.phobert.encoder.layer.1.attention.output.dense.weight', 'embedder.phobert.encoder.layer.1.attention.output.dense.bias', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.intermediate.dense.weight', 'embedder.phobert.encoder.layer.1.intermediate.dense.bias', 'embedder.phobert.encoder.layer.1.output.dense.weight', 'embedder.phobert.encoder.layer.1.output.dense.bias', 'embedder.phobert.encoder.layer.1.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.attention.self.query.weight', 'embedder.phobert.encoder.layer.2.attention.self.query.bias', 'embedder.phobert.encoder.layer.2.attention.self.key.weight', 'embedder.phobert.encoder.layer.2.attention.self.key.bias', 'embedder.phobert.encoder.layer.2.attention.self.value.weight', 'embedder.phobert.encoder.layer.2.attention.self.value.bias', 'embedder.phobert.encoder.layer.2.attention.output.dense.weight', 'embedder.phobert.encoder.layer.2.attention.output.dense.bias', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.intermediate.dense.weight', 'embedder.phobert.encoder.layer.2.intermediate.dense.bias', 'embedder.phobert.encoder.layer.2.output.dense.weight', 'embedder.phobert.encoder.layer.2.output.dense.bias', 'embedder.phobert.encoder.layer.2.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.attention.self.query.weight', 'embedder.phobert.encoder.layer.3.attention.self.query.bias', 'embedder.phobert.encoder.layer.3.attention.self.key.weight', 'embedder.phobert.encoder.layer.3.attention.self.key.bias', 'embedder.phobert.encoder.layer.3.attention.self.value.weight', 'embedder.phobert.encoder.layer.3.attention.self.value.bias', 'embedder.phobert.encoder.layer.3.attention.output.dense.weight', 'embedder.phobert.encoder.layer.3.attention.output.dense.bias', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.intermediate.dense.weight', 'embedder.phobert.encoder.layer.3.intermediate.dense.bias', 'embedder.phobert.encoder.layer.3.output.dense.weight', 'embedder.phobert.encoder.layer.3.output.dense.bias', 'embedder.phobert.encoder.layer.3.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.attention.self.query.weight', 'embedder.phobert.encoder.layer.4.attention.self.query.bias', 'embedder.phobert.encoder.layer.4.attention.self.key.weight', 'embedder.phobert.encoder.layer.4.attention.self.key.bias', 'embedder.phobert.encoder.layer.4.attention.self.value.weight', 'embedder.phobert.encoder.layer.4.attention.self.value.bias', 'embedder.phobert.encoder.layer.4.attention.output.dense.weight', 'embedder.phobert.encoder.layer.4.attention.output.dense.bias', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.intermediate.dense.weight', 'embedder.phobert.encoder.layer.4.intermediate.dense.bias', 'embedder.phobert.encoder.layer.4.output.dense.weight', 'embedder.phobert.encoder.layer.4.output.dense.bias', 'embedder.phobert.encoder.layer.4.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.attention.self.query.weight', 'embedder.phobert.encoder.layer.5.attention.self.query.bias', 'embedder.phobert.encoder.layer.5.attention.self.key.weight', 'embedder.phobert.encoder.layer.5.attention.self.key.bias', 'embedder.phobert.encoder.layer.5.attention.self.value.weight', 'embedder.phobert.encoder.layer.5.attention.self.value.bias', 'embedder.phobert.encoder.layer.5.attention.output.dense.weight', 'embedder.phobert.encoder.layer.5.attention.output.dense.bias', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.intermediate.dense.weight', 'embedder.phobert.encoder.layer.5.intermediate.dense.bias', 'embedder.phobert.encoder.layer.5.output.dense.weight', 'embedder.phobert.encoder.layer.5.output.dense.bias', 'embedder.phobert.encoder.layer.5.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.attention.self.query.weight', 'embedder.phobert.encoder.layer.6.attention.self.query.bias', 'embedder.phobert.encoder.layer.6.attention.self.key.weight', 'embedder.phobert.encoder.layer.6.attention.self.key.bias', 'embedder.phobert.encoder.layer.6.attention.self.value.weight', 'embedder.phobert.encoder.layer.6.attention.self.value.bias', 'embedder.phobert.encoder.layer.6.attention.output.dense.weight', 'embedder.phobert.encoder.layer.6.attention.output.dense.bias', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.intermediate.dense.weight', 'embedder.phobert.encoder.layer.6.intermediate.dense.bias', 'embedder.phobert.encoder.layer.6.output.dense.weight', 'embedder.phobert.encoder.layer.6.output.dense.bias', 'embedder.phobert.encoder.layer.6.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.attention.self.query.weight', 'embedder.phobert.encoder.layer.7.attention.self.query.bias', 'embedder.phobert.encoder.layer.7.attention.self.key.weight', 'embedder.phobert.encoder.layer.7.attention.self.key.bias', 'embedder.phobert.encoder.layer.7.attention.self.value.weight', 'embedder.phobert.encoder.layer.7.attention.self.value.bias', 'embedder.phobert.encoder.layer.7.attention.output.dense.weight', 'embedder.phobert.encoder.layer.7.attention.output.dense.bias', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.intermediate.dense.weight', 'embedder.phobert.encoder.layer.7.intermediate.dense.bias', 'embedder.phobert.encoder.layer.7.output.dense.weight', 'embedder.phobert.encoder.layer.7.output.dense.bias', 'embedder.phobert.encoder.layer.7.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.attention.self.query.weight', 'embedder.phobert.encoder.layer.8.attention.self.query.bias', 'embedder.phobert.encoder.layer.8.attention.self.key.weight', 'embedder.phobert.encoder.layer.8.attention.self.key.bias', 'embedder.phobert.encoder.layer.8.attention.self.value.weight', 'embedder.phobert.encoder.layer.8.attention.self.value.bias', 'embedder.phobert.encoder.layer.8.attention.output.dense.weight', 'embedder.phobert.encoder.layer.8.attention.output.dense.bias', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.intermediate.dense.weight', 'embedder.phobert.encoder.layer.8.intermediate.dense.bias', 'embedder.phobert.encoder.layer.8.output.dense.weight', 'embedder.phobert.encoder.layer.8.output.dense.bias', 'embedder.phobert.encoder.layer.8.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.attention.self.query.weight', 'embedder.phobert.encoder.layer.9.attention.self.query.bias', 'embedder.phobert.encoder.layer.9.attention.self.key.weight', 'embedder.phobert.encoder.layer.9.attention.self.key.bias', 'embedder.phobert.encoder.layer.9.attention.self.value.weight', 'embedder.phobert.encoder.layer.9.attention.self.value.bias', 'embedder.phobert.encoder.layer.9.attention.output.dense.weight', 'embedder.phobert.encoder.layer.9.attention.output.dense.bias', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.intermediate.dense.weight', 'embedder.phobert.encoder.layer.9.intermediate.dense.bias', 'embedder.phobert.encoder.layer.9.output.dense.weight', 'embedder.phobert.encoder.layer.9.output.dense.bias', 'embedder.phobert.encoder.layer.9.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.attention.self.query.weight', 'embedder.phobert.encoder.layer.10.attention.self.query.bias', 'embedder.phobert.encoder.layer.10.attention.self.key.weight', 'embedder.phobert.encoder.layer.10.attention.self.key.bias', 'embedder.phobert.encoder.layer.10.attention.self.value.weight', 'embedder.phobert.encoder.layer.10.attention.self.value.bias', 'embedder.phobert.encoder.layer.10.attention.output.dense.weight', 'embedder.phobert.encoder.layer.10.attention.output.dense.bias', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.intermediate.dense.weight', 'embedder.phobert.encoder.layer.10.intermediate.dense.bias', 'embedder.phobert.encoder.layer.10.output.dense.weight', 'embedder.phobert.encoder.layer.10.output.dense.bias', 'embedder.phobert.encoder.layer.10.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.attention.self.query.weight', 'embedder.phobert.encoder.layer.11.attention.self.query.bias', 'embedder.phobert.encoder.layer.11.attention.self.key.weight', 'embedder.phobert.encoder.layer.11.attention.self.key.bias', 'embedder.phobert.encoder.layer.11.attention.self.value.weight', 'embedder.phobert.encoder.layer.11.attention.self.value.bias', 'embedder.phobert.encoder.layer.11.attention.output.dense.weight', 'embedder.phobert.encoder.layer.11.attention.output.dense.bias', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.intermediate.dense.weight', 'embedder.phobert.encoder.layer.11.intermediate.dense.bias', 'embedder.phobert.encoder.layer.11.output.dense.weight', 'embedder.phobert.encoder.layer.11.output.dense.bias', 'embedder.phobert.encoder.layer.11.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.output.LayerNorm.bias', 'embedder.phobert.pooler.dense.weight', 'embedder.phobert.pooler.dense.bias']\n",
            "freezed layer: []\n",
            "\n",
            "### Loading optimizer state dict\n",
            "\n",
            "Epoch:   0% 0/15 [00:00<?, ?it/s]Train loss: total - 8.058031921846514e-05, classifier - 8.058031921846514e-05, sentiment - 0.1726701401275863\n",
            "Validation loss: total - 2.06397135498417e-06, classifier - 2.06397135498417e-06, sentiment - 0.17404259034261413\n",
            "Saving model at epoch 0 with validation loss of 2.06397135498417e-06\n",
            "\n",
            "\n",
            "Epoch:   7% 1/15 [02:51<40:00, 171.48s/it]Train loss: total - 1.4296483254253216e-06, classifier - 1.4296483254253216e-06, sentiment - 0.1727447664528631\n",
            "Validation loss: total - 1.0140481873433998e-06, classifier - 1.0140481873433998e-06, sentiment - 0.17409040548001267\n",
            "Saving model at epoch 1 with validation loss of 1.0140481873433998e-06\n",
            "\n",
            "\n",
            "Epoch:  13% 2/15 [05:48<37:52, 174.77s/it]Train loss: total - 7.746711163760172e-07, classifier - 7.746711163760172e-07, sentiment - 0.17276744543129235\n",
            "Validation loss: total - 6.02425674163392e-07, classifier - 6.02425674163392e-07, sentiment - 0.1741082043200284\n",
            "Saving model at epoch 2 with validation loss of 6.02425674163392e-07\n",
            "\n",
            "\n",
            "Epoch:  20% 3/15 [08:50<35:36, 178.04s/it]Train loss: total - 4.881533981115898e-07, classifier - 4.881533981115898e-07, sentiment - 0.17278632248167317\n",
            "Validation loss: total - 4.009307265717501e-07, classifier - 4.009307265717501e-07, sentiment - 0.17411731378178674\n",
            "Saving model at epoch 3 with validation loss of 4.009307265717501e-07\n",
            "\n",
            "\n",
            "Epoch:  27% 4/15 [11:50<32:47, 178.87s/it]Train loss: total - 3.358208838395824e-07, classifier - 3.358208838395824e-07, sentiment - 0.17278932012548417\n",
            "Validation loss: total - 2.8630867608389506e-07, classifier - 2.8630867608389506e-07, sentiment - 0.17412368346582585\n",
            "Saving model at epoch 4 with validation loss of 2.8630867608389506e-07\n",
            "\n",
            "\n",
            "Epoch:  33% 5/15 [14:50<29:50, 179.07s/it]Train loss: total - 2.4489088081569996e-07, classifier - 2.4489088081569996e-07, sentiment - 0.17279680768616157\n",
            "Validation loss: total - 2.1385059074823745e-07, classifier - 2.1385059074823745e-07, sentiment - 0.17413531730257845\n",
            "Saving model at epoch 5 with validation loss of 2.1385059074823745e-07\n",
            "\n",
            "\n",
            "Epoch:  40% 6/15 [17:50<26:56, 179.65s/it]Train loss: total - 1.8636531769064176e-07, classifier - 1.8636531769064176e-07, sentiment - 0.1727994552908903\n",
            "Validation loss: total - 1.6515267235576665e-07, classifier - 1.6515267235576665e-07, sentiment - 0.17413618251131255\n",
            "Saving model at epoch 6 with validation loss of 1.6515267235576665e-07\n",
            "\n",
            "\n",
            "Epoch:  47% 7/15 [20:50<23:58, 179.81s/it]Train loss: total - 1.4634864526500658e-07, classifier - 1.4634864526500658e-07, sentiment - 0.17279789029036738\n",
            "Validation loss: total - 1.317286417536959e-07, classifier - 1.317286417536959e-07, sentiment - 0.17413766065663863\n",
            "Saving model at epoch 7 with validation loss of 1.317286417536959e-07\n",
            "\n",
            "\n",
            "Epoch:  53% 8/15 [23:52<21:01, 180.27s/it]Train loss: total - 1.175145194163096e-07, classifier - 1.175145194163096e-07, sentiment - 0.17280238343164245\n",
            "Validation loss: total - 1.0734300278899423e-07, classifier - 1.0734300278899423e-07, sentiment - 0.1741398884607356\n",
            "Saving model at epoch 8 with validation loss of 1.0734300278899423e-07\n",
            "\n",
            "\n",
            "Epoch:  60% 9/15 [26:51<17:58, 179.81s/it]Train loss: total - 9.638899609089296e-08, classifier - 9.638899609089296e-08, sentiment - 0.17280402778606896\n",
            "Validation loss: total - 8.911704279845796e-08, classifier - 8.911704279845796e-08, sentiment - 0.17414196467167942\n",
            "Saving model at epoch 9 with validation loss of 8.911704279845796e-08\n",
            "\n",
            "\n",
            "Epoch:  67% 10/15 [29:50<14:58, 179.66s/it]Train loss: total - 8.017145207576505e-08, classifier - 8.017145207576505e-08, sentiment - 0.1728097839101191\n",
            "Validation loss: total - 7.398302468878804e-08, classifier - 7.398302468878804e-08, sentiment - 0.17414752456011856\n",
            "Saving model at epoch 10 with validation loss of 7.398302468878804e-08\n",
            "\n",
            "\n",
            "Epoch:  73% 11/15 [32:49<11:58, 179.64s/it]Train loss: total - 6.764376857002629e-08, classifier - 6.764376857002629e-08, sentiment - 0.17280588989281617\n",
            "Validation loss: total - 6.29000388058756e-08, classifier - 6.29000388058756e-08, sentiment - 0.17414758071898162\n",
            "Saving model at epoch 11 with validation loss of 6.29000388058756e-08\n",
            "\n",
            "\n",
            "Epoch:  80% 12/15 [35:51<09:00, 180.12s/it]Train loss: total - 5.7696543261382423e-08, classifier - 5.7696543261382423e-08, sentiment - 0.17281319247661486\n",
            "Validation loss: total - 5.4002528088881456e-08, classifier - 5.4002528088881456e-08, sentiment - 0.17414879592052815\n",
            "Saving model at epoch 12 with validation loss of 5.4002528088881456e-08\n",
            "\n",
            "\n",
            "Epoch:  87% 13/15 [38:54<06:02, 181.15s/it]Train loss: total - 4.963402527842612e-08, classifier - 4.963402527842612e-08, sentiment - 0.17281763599270342\n",
            "Validation loss: total - 4.6554505445806364e-08, classifier - 4.6554505445806364e-08, sentiment - 0.1741522470017334\n",
            "Saving model at epoch 13 with validation loss of 4.6554505445806364e-08\n",
            "\n",
            "\n",
            "Epoch:  93% 14/15 [41:55<03:00, 180.92s/it]Train loss: total - 4.301131868580291e-08, classifier - 4.301131868580291e-08, sentiment - 0.1728263983760407\n",
            "Validation loss: total - 4.0515809090522006e-08, classifier - 4.0515809090522006e-08, sentiment - 0.17415339194712232\n",
            "Saving model at epoch 14 with validation loss of 4.0515809090522006e-08\n",
            "\n",
            "\n",
            "Epoch: 100% 15/15 [44:57<00:00, 179.82s/it]\n",
            "### Loading pretrained model from log/model_absa.bin\n",
            "loaded layer: ['log_vars', 'embedding_layer_fc.weight', 'embedding_layer_fc.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l1', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'embedding_layer_aspect_attentions.0.W.weight', 'embedding_layer_aspect_attentions.0.W.bias', 'embedding_layer_aspect_attentions.0.uw.weight', 'embedding_layer_aspect_attentions.1.W.weight', 'embedding_layer_aspect_attentions.1.W.bias', 'embedding_layer_aspect_attentions.1.uw.weight', 'embedding_layer_aspect_attentions.2.W.weight', 'embedding_layer_aspect_attentions.2.W.bias', 'embedding_layer_aspect_attentions.2.uw.weight', 'embedding_layer_aspect_attentions.3.W.weight', 'embedding_layer_aspect_attentions.3.W.bias', 'embedding_layer_aspect_attentions.3.uw.weight', 'category_fcs.0.weight', 'category_fcs.0.bias', 'category_fcs.1.weight', 'category_fcs.1.bias', 'category_fcs.2.weight', 'category_fcs.2.bias', 'category_fcs.3.weight', 'category_fcs.3.bias', 'sentiment_fcs.0.0.weight', 'sentiment_fcs.0.0.bias', 'sentiment_fcs.0.2.weight', 'sentiment_fcs.0.2.bias', 'sentiment_fcs.1.0.weight', 'sentiment_fcs.1.0.bias', 'sentiment_fcs.1.2.weight', 'sentiment_fcs.1.2.bias', 'sentiment_fcs.2.0.weight', 'sentiment_fcs.2.0.bias', 'sentiment_fcs.2.2.weight', 'sentiment_fcs.2.2.bias', 'sentiment_fcs.3.0.weight', 'sentiment_fcs.3.0.bias', 'sentiment_fcs.3.2.weight', 'sentiment_fcs.3.2.bias']\n",
            "non-loaded layer: ['embedder.phobert.embeddings.word_embeddings.weight', 'embedder.phobert.embeddings.position_embeddings.weight', 'embedder.phobert.embeddings.token_type_embeddings.weight', 'embedder.phobert.embeddings.LayerNorm.weight', 'embedder.phobert.embeddings.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.attention.self.query.weight', 'embedder.phobert.encoder.layer.0.attention.self.query.bias', 'embedder.phobert.encoder.layer.0.attention.self.key.weight', 'embedder.phobert.encoder.layer.0.attention.self.key.bias', 'embedder.phobert.encoder.layer.0.attention.self.value.weight', 'embedder.phobert.encoder.layer.0.attention.self.value.bias', 'embedder.phobert.encoder.layer.0.attention.output.dense.weight', 'embedder.phobert.encoder.layer.0.attention.output.dense.bias', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.intermediate.dense.weight', 'embedder.phobert.encoder.layer.0.intermediate.dense.bias', 'embedder.phobert.encoder.layer.0.output.dense.weight', 'embedder.phobert.encoder.layer.0.output.dense.bias', 'embedder.phobert.encoder.layer.0.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.attention.self.query.weight', 'embedder.phobert.encoder.layer.1.attention.self.query.bias', 'embedder.phobert.encoder.layer.1.attention.self.key.weight', 'embedder.phobert.encoder.layer.1.attention.self.key.bias', 'embedder.phobert.encoder.layer.1.attention.self.value.weight', 'embedder.phobert.encoder.layer.1.attention.self.value.bias', 'embedder.phobert.encoder.layer.1.attention.output.dense.weight', 'embedder.phobert.encoder.layer.1.attention.output.dense.bias', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.intermediate.dense.weight', 'embedder.phobert.encoder.layer.1.intermediate.dense.bias', 'embedder.phobert.encoder.layer.1.output.dense.weight', 'embedder.phobert.encoder.layer.1.output.dense.bias', 'embedder.phobert.encoder.layer.1.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.attention.self.query.weight', 'embedder.phobert.encoder.layer.2.attention.self.query.bias', 'embedder.phobert.encoder.layer.2.attention.self.key.weight', 'embedder.phobert.encoder.layer.2.attention.self.key.bias', 'embedder.phobert.encoder.layer.2.attention.self.value.weight', 'embedder.phobert.encoder.layer.2.attention.self.value.bias', 'embedder.phobert.encoder.layer.2.attention.output.dense.weight', 'embedder.phobert.encoder.layer.2.attention.output.dense.bias', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.intermediate.dense.weight', 'embedder.phobert.encoder.layer.2.intermediate.dense.bias', 'embedder.phobert.encoder.layer.2.output.dense.weight', 'embedder.phobert.encoder.layer.2.output.dense.bias', 'embedder.phobert.encoder.layer.2.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.attention.self.query.weight', 'embedder.phobert.encoder.layer.3.attention.self.query.bias', 'embedder.phobert.encoder.layer.3.attention.self.key.weight', 'embedder.phobert.encoder.layer.3.attention.self.key.bias', 'embedder.phobert.encoder.layer.3.attention.self.value.weight', 'embedder.phobert.encoder.layer.3.attention.self.value.bias', 'embedder.phobert.encoder.layer.3.attention.output.dense.weight', 'embedder.phobert.encoder.layer.3.attention.output.dense.bias', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.intermediate.dense.weight', 'embedder.phobert.encoder.layer.3.intermediate.dense.bias', 'embedder.phobert.encoder.layer.3.output.dense.weight', 'embedder.phobert.encoder.layer.3.output.dense.bias', 'embedder.phobert.encoder.layer.3.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.attention.self.query.weight', 'embedder.phobert.encoder.layer.4.attention.self.query.bias', 'embedder.phobert.encoder.layer.4.attention.self.key.weight', 'embedder.phobert.encoder.layer.4.attention.self.key.bias', 'embedder.phobert.encoder.layer.4.attention.self.value.weight', 'embedder.phobert.encoder.layer.4.attention.self.value.bias', 'embedder.phobert.encoder.layer.4.attention.output.dense.weight', 'embedder.phobert.encoder.layer.4.attention.output.dense.bias', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.intermediate.dense.weight', 'embedder.phobert.encoder.layer.4.intermediate.dense.bias', 'embedder.phobert.encoder.layer.4.output.dense.weight', 'embedder.phobert.encoder.layer.4.output.dense.bias', 'embedder.phobert.encoder.layer.4.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.attention.self.query.weight', 'embedder.phobert.encoder.layer.5.attention.self.query.bias', 'embedder.phobert.encoder.layer.5.attention.self.key.weight', 'embedder.phobert.encoder.layer.5.attention.self.key.bias', 'embedder.phobert.encoder.layer.5.attention.self.value.weight', 'embedder.phobert.encoder.layer.5.attention.self.value.bias', 'embedder.phobert.encoder.layer.5.attention.output.dense.weight', 'embedder.phobert.encoder.layer.5.attention.output.dense.bias', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.intermediate.dense.weight', 'embedder.phobert.encoder.layer.5.intermediate.dense.bias', 'embedder.phobert.encoder.layer.5.output.dense.weight', 'embedder.phobert.encoder.layer.5.output.dense.bias', 'embedder.phobert.encoder.layer.5.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.attention.self.query.weight', 'embedder.phobert.encoder.layer.6.attention.self.query.bias', 'embedder.phobert.encoder.layer.6.attention.self.key.weight', 'embedder.phobert.encoder.layer.6.attention.self.key.bias', 'embedder.phobert.encoder.layer.6.attention.self.value.weight', 'embedder.phobert.encoder.layer.6.attention.self.value.bias', 'embedder.phobert.encoder.layer.6.attention.output.dense.weight', 'embedder.phobert.encoder.layer.6.attention.output.dense.bias', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.intermediate.dense.weight', 'embedder.phobert.encoder.layer.6.intermediate.dense.bias', 'embedder.phobert.encoder.layer.6.output.dense.weight', 'embedder.phobert.encoder.layer.6.output.dense.bias', 'embedder.phobert.encoder.layer.6.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.attention.self.query.weight', 'embedder.phobert.encoder.layer.7.attention.self.query.bias', 'embedder.phobert.encoder.layer.7.attention.self.key.weight', 'embedder.phobert.encoder.layer.7.attention.self.key.bias', 'embedder.phobert.encoder.layer.7.attention.self.value.weight', 'embedder.phobert.encoder.layer.7.attention.self.value.bias', 'embedder.phobert.encoder.layer.7.attention.output.dense.weight', 'embedder.phobert.encoder.layer.7.attention.output.dense.bias', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.intermediate.dense.weight', 'embedder.phobert.encoder.layer.7.intermediate.dense.bias', 'embedder.phobert.encoder.layer.7.output.dense.weight', 'embedder.phobert.encoder.layer.7.output.dense.bias', 'embedder.phobert.encoder.layer.7.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.attention.self.query.weight', 'embedder.phobert.encoder.layer.8.attention.self.query.bias', 'embedder.phobert.encoder.layer.8.attention.self.key.weight', 'embedder.phobert.encoder.layer.8.attention.self.key.bias', 'embedder.phobert.encoder.layer.8.attention.self.value.weight', 'embedder.phobert.encoder.layer.8.attention.self.value.bias', 'embedder.phobert.encoder.layer.8.attention.output.dense.weight', 'embedder.phobert.encoder.layer.8.attention.output.dense.bias', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.intermediate.dense.weight', 'embedder.phobert.encoder.layer.8.intermediate.dense.bias', 'embedder.phobert.encoder.layer.8.output.dense.weight', 'embedder.phobert.encoder.layer.8.output.dense.bias', 'embedder.phobert.encoder.layer.8.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.attention.self.query.weight', 'embedder.phobert.encoder.layer.9.attention.self.query.bias', 'embedder.phobert.encoder.layer.9.attention.self.key.weight', 'embedder.phobert.encoder.layer.9.attention.self.key.bias', 'embedder.phobert.encoder.layer.9.attention.self.value.weight', 'embedder.phobert.encoder.layer.9.attention.self.value.bias', 'embedder.phobert.encoder.layer.9.attention.output.dense.weight', 'embedder.phobert.encoder.layer.9.attention.output.dense.bias', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.intermediate.dense.weight', 'embedder.phobert.encoder.layer.9.intermediate.dense.bias', 'embedder.phobert.encoder.layer.9.output.dense.weight', 'embedder.phobert.encoder.layer.9.output.dense.bias', 'embedder.phobert.encoder.layer.9.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.attention.self.query.weight', 'embedder.phobert.encoder.layer.10.attention.self.query.bias', 'embedder.phobert.encoder.layer.10.attention.self.key.weight', 'embedder.phobert.encoder.layer.10.attention.self.key.bias', 'embedder.phobert.encoder.layer.10.attention.self.value.weight', 'embedder.phobert.encoder.layer.10.attention.self.value.bias', 'embedder.phobert.encoder.layer.10.attention.output.dense.weight', 'embedder.phobert.encoder.layer.10.attention.output.dense.bias', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.intermediate.dense.weight', 'embedder.phobert.encoder.layer.10.intermediate.dense.bias', 'embedder.phobert.encoder.layer.10.output.dense.weight', 'embedder.phobert.encoder.layer.10.output.dense.bias', 'embedder.phobert.encoder.layer.10.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.attention.self.query.weight', 'embedder.phobert.encoder.layer.11.attention.self.query.bias', 'embedder.phobert.encoder.layer.11.attention.self.key.weight', 'embedder.phobert.encoder.layer.11.attention.self.key.bias', 'embedder.phobert.encoder.layer.11.attention.self.value.weight', 'embedder.phobert.encoder.layer.11.attention.self.value.bias', 'embedder.phobert.encoder.layer.11.attention.output.dense.weight', 'embedder.phobert.encoder.layer.11.attention.output.dense.bias', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.intermediate.dense.weight', 'embedder.phobert.encoder.layer.11.intermediate.dense.bias', 'embedder.phobert.encoder.layer.11.output.dense.weight', 'embedder.phobert.encoder.layer.11.output.dense.bias', 'embedder.phobert.encoder.layer.11.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.output.LayerNorm.bias', 'embedder.phobert.pooler.dense.weight', 'embedder.phobert.pooler.dense.bias']\n",
            "freezed layer: ['lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l1', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'sentiment_fcs.0.0.weight', 'sentiment_fcs.0.0.bias', 'sentiment_fcs.0.2.weight', 'sentiment_fcs.0.2.bias', 'sentiment_fcs.1.0.weight', 'sentiment_fcs.1.0.bias', 'sentiment_fcs.1.2.weight', 'sentiment_fcs.1.2.bias', 'sentiment_fcs.2.0.weight', 'sentiment_fcs.2.0.bias', 'sentiment_fcs.2.2.weight', 'sentiment_fcs.2.2.bias', 'sentiment_fcs.3.0.weight', 'sentiment_fcs.3.0.bias', 'sentiment_fcs.3.2.weight', 'sentiment_fcs.3.2.bias']\n",
            "\n",
            "Epoch:   0% 0/15 [01:18<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/Trainer.py\", line 187, in <module>\n",
            "    model, train_loss_set, valid_loss_set = fit(model=model,\\\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/Trainer.py\", line 42, in fit\n",
            "    batch = tuple(t.to(device) for t in batch)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/Trainer.py\", line 42, in <genexpr>\n",
            "    batch = tuple(t.to(device) for t in batch)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/ABSA-MLQ/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5iGoXmLYaNu",
        "outputId": "af755f8a-6068-4fcf-e090-9d5d9d07ac0f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Loading config {'aspect': ['character', 'content', 'scene', 'sound'], 'labels': ['x', 'o', 'n', 'p'], 'pretrained': 'vinai/phobert-base-v2', 'use_lstm': True, 'num_layers_lstm': 1, 'word_embedding_dim': 256, 'num_embeddings': 256, 'batch_size': 32, 'num_workers': 2, 'num_epochs': 15, 'train_file': 'dataset/train_processed.csv', 'val_file': 'dataset/dev_processed.csv', 'test_file': 'dataset/test_processed.csv', 'freeze_embedder': False, 'acd_warmup': 15, 'acd_only': False, 'acsc_only': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'acd_loss_weight': 1.0, 'acsc_loss_weight': 1.0, 'saved_model': 'log/model_absa.bin', 'model_save_path': 'log/model_absa.bin', 'callbacks': [{'name': 'EarlyStopping', 'patience': 5, 'monitor': 'val_loss'}, {'name': 'ModelCheckpoint', 'filepath': 'log/best_model.bin', 'monitor': 'val_loss', 'save_best_only': True}], 'device': device(type='cuda', index=0)}\n",
            "2025-01-05 10:44:09.775237: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/model_utils.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path)\n",
            "### Loading pretrained model from log/model_absa.bin\n",
            "loaded layer: ['log_vars', 'embedding_layer_fc.weight', 'embedding_layer_fc.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'embedding_layer_aspect_attentions.0.W.weight', 'embedding_layer_aspect_attentions.0.W.bias', 'embedding_layer_aspect_attentions.0.uw.weight', 'embedding_layer_aspect_attentions.1.W.weight', 'embedding_layer_aspect_attentions.1.W.bias', 'embedding_layer_aspect_attentions.1.uw.weight', 'embedding_layer_aspect_attentions.2.W.weight', 'embedding_layer_aspect_attentions.2.W.bias', 'embedding_layer_aspect_attentions.2.uw.weight', 'embedding_layer_aspect_attentions.3.W.weight', 'embedding_layer_aspect_attentions.3.W.bias', 'embedding_layer_aspect_attentions.3.uw.weight', 'category_fcs.0.weight', 'category_fcs.0.bias', 'category_fcs.1.weight', 'category_fcs.1.bias', 'category_fcs.2.weight', 'category_fcs.2.bias', 'category_fcs.3.weight', 'category_fcs.3.bias', 'sentiment_fcs.0.0.weight', 'sentiment_fcs.0.0.bias', 'sentiment_fcs.0.2.weight', 'sentiment_fcs.0.2.bias', 'sentiment_fcs.1.0.weight', 'sentiment_fcs.1.0.bias', 'sentiment_fcs.1.2.weight', 'sentiment_fcs.1.2.bias', 'sentiment_fcs.2.0.weight', 'sentiment_fcs.2.0.bias', 'sentiment_fcs.2.2.weight', 'sentiment_fcs.2.2.bias', 'sentiment_fcs.3.0.weight', 'sentiment_fcs.3.0.bias', 'sentiment_fcs.3.2.weight', 'sentiment_fcs.3.2.bias']\n",
            "non-loaded layer: ['embedder.phobert.embeddings.word_embeddings.weight', 'embedder.phobert.embeddings.position_embeddings.weight', 'embedder.phobert.embeddings.token_type_embeddings.weight', 'embedder.phobert.embeddings.LayerNorm.weight', 'embedder.phobert.embeddings.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.attention.self.query.weight', 'embedder.phobert.encoder.layer.0.attention.self.query.bias', 'embedder.phobert.encoder.layer.0.attention.self.key.weight', 'embedder.phobert.encoder.layer.0.attention.self.key.bias', 'embedder.phobert.encoder.layer.0.attention.self.value.weight', 'embedder.phobert.encoder.layer.0.attention.self.value.bias', 'embedder.phobert.encoder.layer.0.attention.output.dense.weight', 'embedder.phobert.encoder.layer.0.attention.output.dense.bias', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.0.intermediate.dense.weight', 'embedder.phobert.encoder.layer.0.intermediate.dense.bias', 'embedder.phobert.encoder.layer.0.output.dense.weight', 'embedder.phobert.encoder.layer.0.output.dense.bias', 'embedder.phobert.encoder.layer.0.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.0.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.attention.self.query.weight', 'embedder.phobert.encoder.layer.1.attention.self.query.bias', 'embedder.phobert.encoder.layer.1.attention.self.key.weight', 'embedder.phobert.encoder.layer.1.attention.self.key.bias', 'embedder.phobert.encoder.layer.1.attention.self.value.weight', 'embedder.phobert.encoder.layer.1.attention.self.value.bias', 'embedder.phobert.encoder.layer.1.attention.output.dense.weight', 'embedder.phobert.encoder.layer.1.attention.output.dense.bias', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.1.intermediate.dense.weight', 'embedder.phobert.encoder.layer.1.intermediate.dense.bias', 'embedder.phobert.encoder.layer.1.output.dense.weight', 'embedder.phobert.encoder.layer.1.output.dense.bias', 'embedder.phobert.encoder.layer.1.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.1.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.attention.self.query.weight', 'embedder.phobert.encoder.layer.2.attention.self.query.bias', 'embedder.phobert.encoder.layer.2.attention.self.key.weight', 'embedder.phobert.encoder.layer.2.attention.self.key.bias', 'embedder.phobert.encoder.layer.2.attention.self.value.weight', 'embedder.phobert.encoder.layer.2.attention.self.value.bias', 'embedder.phobert.encoder.layer.2.attention.output.dense.weight', 'embedder.phobert.encoder.layer.2.attention.output.dense.bias', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.2.intermediate.dense.weight', 'embedder.phobert.encoder.layer.2.intermediate.dense.bias', 'embedder.phobert.encoder.layer.2.output.dense.weight', 'embedder.phobert.encoder.layer.2.output.dense.bias', 'embedder.phobert.encoder.layer.2.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.2.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.attention.self.query.weight', 'embedder.phobert.encoder.layer.3.attention.self.query.bias', 'embedder.phobert.encoder.layer.3.attention.self.key.weight', 'embedder.phobert.encoder.layer.3.attention.self.key.bias', 'embedder.phobert.encoder.layer.3.attention.self.value.weight', 'embedder.phobert.encoder.layer.3.attention.self.value.bias', 'embedder.phobert.encoder.layer.3.attention.output.dense.weight', 'embedder.phobert.encoder.layer.3.attention.output.dense.bias', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.3.intermediate.dense.weight', 'embedder.phobert.encoder.layer.3.intermediate.dense.bias', 'embedder.phobert.encoder.layer.3.output.dense.weight', 'embedder.phobert.encoder.layer.3.output.dense.bias', 'embedder.phobert.encoder.layer.3.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.3.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.attention.self.query.weight', 'embedder.phobert.encoder.layer.4.attention.self.query.bias', 'embedder.phobert.encoder.layer.4.attention.self.key.weight', 'embedder.phobert.encoder.layer.4.attention.self.key.bias', 'embedder.phobert.encoder.layer.4.attention.self.value.weight', 'embedder.phobert.encoder.layer.4.attention.self.value.bias', 'embedder.phobert.encoder.layer.4.attention.output.dense.weight', 'embedder.phobert.encoder.layer.4.attention.output.dense.bias', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.4.intermediate.dense.weight', 'embedder.phobert.encoder.layer.4.intermediate.dense.bias', 'embedder.phobert.encoder.layer.4.output.dense.weight', 'embedder.phobert.encoder.layer.4.output.dense.bias', 'embedder.phobert.encoder.layer.4.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.4.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.attention.self.query.weight', 'embedder.phobert.encoder.layer.5.attention.self.query.bias', 'embedder.phobert.encoder.layer.5.attention.self.key.weight', 'embedder.phobert.encoder.layer.5.attention.self.key.bias', 'embedder.phobert.encoder.layer.5.attention.self.value.weight', 'embedder.phobert.encoder.layer.5.attention.self.value.bias', 'embedder.phobert.encoder.layer.5.attention.output.dense.weight', 'embedder.phobert.encoder.layer.5.attention.output.dense.bias', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.5.intermediate.dense.weight', 'embedder.phobert.encoder.layer.5.intermediate.dense.bias', 'embedder.phobert.encoder.layer.5.output.dense.weight', 'embedder.phobert.encoder.layer.5.output.dense.bias', 'embedder.phobert.encoder.layer.5.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.5.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.attention.self.query.weight', 'embedder.phobert.encoder.layer.6.attention.self.query.bias', 'embedder.phobert.encoder.layer.6.attention.self.key.weight', 'embedder.phobert.encoder.layer.6.attention.self.key.bias', 'embedder.phobert.encoder.layer.6.attention.self.value.weight', 'embedder.phobert.encoder.layer.6.attention.self.value.bias', 'embedder.phobert.encoder.layer.6.attention.output.dense.weight', 'embedder.phobert.encoder.layer.6.attention.output.dense.bias', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.6.intermediate.dense.weight', 'embedder.phobert.encoder.layer.6.intermediate.dense.bias', 'embedder.phobert.encoder.layer.6.output.dense.weight', 'embedder.phobert.encoder.layer.6.output.dense.bias', 'embedder.phobert.encoder.layer.6.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.6.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.attention.self.query.weight', 'embedder.phobert.encoder.layer.7.attention.self.query.bias', 'embedder.phobert.encoder.layer.7.attention.self.key.weight', 'embedder.phobert.encoder.layer.7.attention.self.key.bias', 'embedder.phobert.encoder.layer.7.attention.self.value.weight', 'embedder.phobert.encoder.layer.7.attention.self.value.bias', 'embedder.phobert.encoder.layer.7.attention.output.dense.weight', 'embedder.phobert.encoder.layer.7.attention.output.dense.bias', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.7.intermediate.dense.weight', 'embedder.phobert.encoder.layer.7.intermediate.dense.bias', 'embedder.phobert.encoder.layer.7.output.dense.weight', 'embedder.phobert.encoder.layer.7.output.dense.bias', 'embedder.phobert.encoder.layer.7.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.7.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.attention.self.query.weight', 'embedder.phobert.encoder.layer.8.attention.self.query.bias', 'embedder.phobert.encoder.layer.8.attention.self.key.weight', 'embedder.phobert.encoder.layer.8.attention.self.key.bias', 'embedder.phobert.encoder.layer.8.attention.self.value.weight', 'embedder.phobert.encoder.layer.8.attention.self.value.bias', 'embedder.phobert.encoder.layer.8.attention.output.dense.weight', 'embedder.phobert.encoder.layer.8.attention.output.dense.bias', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.8.intermediate.dense.weight', 'embedder.phobert.encoder.layer.8.intermediate.dense.bias', 'embedder.phobert.encoder.layer.8.output.dense.weight', 'embedder.phobert.encoder.layer.8.output.dense.bias', 'embedder.phobert.encoder.layer.8.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.8.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.attention.self.query.weight', 'embedder.phobert.encoder.layer.9.attention.self.query.bias', 'embedder.phobert.encoder.layer.9.attention.self.key.weight', 'embedder.phobert.encoder.layer.9.attention.self.key.bias', 'embedder.phobert.encoder.layer.9.attention.self.value.weight', 'embedder.phobert.encoder.layer.9.attention.self.value.bias', 'embedder.phobert.encoder.layer.9.attention.output.dense.weight', 'embedder.phobert.encoder.layer.9.attention.output.dense.bias', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.9.intermediate.dense.weight', 'embedder.phobert.encoder.layer.9.intermediate.dense.bias', 'embedder.phobert.encoder.layer.9.output.dense.weight', 'embedder.phobert.encoder.layer.9.output.dense.bias', 'embedder.phobert.encoder.layer.9.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.9.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.attention.self.query.weight', 'embedder.phobert.encoder.layer.10.attention.self.query.bias', 'embedder.phobert.encoder.layer.10.attention.self.key.weight', 'embedder.phobert.encoder.layer.10.attention.self.key.bias', 'embedder.phobert.encoder.layer.10.attention.self.value.weight', 'embedder.phobert.encoder.layer.10.attention.self.value.bias', 'embedder.phobert.encoder.layer.10.attention.output.dense.weight', 'embedder.phobert.encoder.layer.10.attention.output.dense.bias', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.10.intermediate.dense.weight', 'embedder.phobert.encoder.layer.10.intermediate.dense.bias', 'embedder.phobert.encoder.layer.10.output.dense.weight', 'embedder.phobert.encoder.layer.10.output.dense.bias', 'embedder.phobert.encoder.layer.10.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.10.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.attention.self.query.weight', 'embedder.phobert.encoder.layer.11.attention.self.query.bias', 'embedder.phobert.encoder.layer.11.attention.self.key.weight', 'embedder.phobert.encoder.layer.11.attention.self.key.bias', 'embedder.phobert.encoder.layer.11.attention.self.value.weight', 'embedder.phobert.encoder.layer.11.attention.self.value.bias', 'embedder.phobert.encoder.layer.11.attention.output.dense.weight', 'embedder.phobert.encoder.layer.11.attention.output.dense.bias', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.attention.output.LayerNorm.bias', 'embedder.phobert.encoder.layer.11.intermediate.dense.weight', 'embedder.phobert.encoder.layer.11.intermediate.dense.bias', 'embedder.phobert.encoder.layer.11.output.dense.weight', 'embedder.phobert.encoder.layer.11.output.dense.bias', 'embedder.phobert.encoder.layer.11.output.LayerNorm.weight', 'embedder.phobert.encoder.layer.11.output.LayerNorm.bias', 'embedder.phobert.pooler.dense.weight', 'embedder.phobert.pooler.dense.bias']\n",
            "freezed layer: []\n",
            "\n",
            "/content/drive/MyDrive/ABSA-MLQ/eval.py:119: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  y = label_encoder_df(test[label_cols].applymap(lambda x: x.lower() if pd.notnull(x) else x)).values.tolist()\n",
            "/content/drive/.shortcut-targets-by-id/1d0XUvYhh6tZQHiVt6cMaSw0OweHZ6FJj/ABSA-MLQ/utils.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return df.replace({'x': 0,\n",
            "[[3, 0, 0, 0], [3, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 2, 0, 0], [0, 3, 3, 3], [0, 1, 0, 0], [0, 3, 0, 0], [0, 2, 0, 0], [0, 0, 0, 1], [0, 0, 2, 0], [1, 0, 0, 0], [0, 3, 3, 0], [3, 3, 1, 0], [3, 3, 3, 0], [3, 3, 3, 3], [1, 3, 3, 0], [1, 0, 0, 0], [3, 0, 0, 0], [0, 0, 0, 0], [3, 0, 0, 0], [3, 2, 0, 0], [0, 3, 3, 3], [0, 0, 0, 0], [0, 3, 3, 0], [3, 0, 3, 0], [0, 0, 0, 1], [1, 0, 3, 3], [0, 0, 3, 0], [0, 0, 1, 0], [0, 2, 0, 0], [2, 2, 0, 0], [0, 0, 3, 3], [0, 3, 1, 0], [0, 3, 3, 0], [3, 2, 2, 0], [3, 3, 3, 0], [1, 0, 0, 0], [0, 0, 2, 0], [0, 0, 2, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 2, 0, 2], [3, 0, 0, 0], [0, 0, 0, 2], [0, 0, 2, 2], [3, 2, 3, 3], [0, 0, 0, 0], [3, 0, 1, 0], [3, 0, 0, 0], [0, 3, 3, 0], [0, 2, 0, 0], [3, 0, 2, 0], [0, 1, 3, 0], [0, 0, 1, 0], [0, 3, 3, 3], [0, 2, 2, 0], [0, 0, 0, 1], [0, 0, 3, 3], [0, 0, 3, 2], [0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 0], [0, 3, 0, 0], [0, 0, 0, 0], [0, 3, 0, 0], [3, 0, 0, 0], [1, 0, 0, 1], [0, 3, 1, 3], [1, 2, 2, 0], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 0], [3, 0, 3, 0], [0, 0, 0, 3], [0, 1, 0, 0], [0, 0, 0, 0], [3, 0, 0, 3], [0, 0, 3, 0], [0, 0, 1, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 2], [0, 0, 2, 2], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 1], [3, 3, 0, 3], [0, 0, 0, 0], [3, 3, 2, 0], [3, 0, 0, 0], [3, 1, 1, 0], [3, 1, 0, 0], [3, 3, 1, 0], [3, 1, 3, 3], [1, 0, 0, 0], [0, 0, 0, 0], [3, 0, 3, 0], [0, 3, 0, 0], [2, 2, 2, 0], [0, 0, 0, 0], [0, 0, 2, 0], [0, 0, 0, 0], [2, 0, 0, 0], [0, 3, 3, 0], [2, 2, 1, 2], [3, 0, 0, 0], [0, 2, 0, 0], [3, 1, 1, 0], [3, 0, 0, 0], [0, 0, 0, 2], [0, 3, 3, 0], [0, 3, 0, 0], [1, 0, 0, 0], [0, 0, 3, 0], [0, 0, 0, 0], [0, 1, 1, 0], [0, 0, 0, 0], [0, 2, 0, 0], [1, 0, 0, 0], [1, 0, 0, 2], [3, 3, 0, 3], [0, 0, 0, 0], [0, 0, 0, 0], [3, 2, 2, 0], [1, 0, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0], [2, 2, 1, 2], [1, 3, 3, 0], [0, 0, 0, 0], [0, 0, 1, 0], [0, 3, 3, 3], [3, 3, 1, 3], [1, 1, 0, 0], [2, 0, 0, 0], [2, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 2, 1, 0], [3, 3, 0, 3], [2, 0, 0, 2], [0, 0, 0, 0], [1, 0, 0, 0], [2, 2, 0, 0], [3, 3, 3, 3], [0, 3, 0, 0], [2, 0, 0, 0], [0, 3, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0], [0, 2, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 3, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 2, 0], [0, 2, 0, 0], [0, 0, 1, 0], [3, 3, 3, 3], [0, 2, 0, 2], [0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 0], [3, 1, 1, 0], [0, 0, 0, 0], [0, 0, 1, 2], [0, 0, 0, 1], [3, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [0, 2, 0, 0], [0, 0, 0, 0], [1, 0, 1, 0], [0, 3, 0, 0], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 2], [1, 2, 3, 1], [0, 0, 0, 0], [1, 3, 0, 0], [0, 3, 3, 0], [3, 1, 0, 0], [0, 0, 0, 0], [0, 3, 3, 0], [0, 2, 0, 0], [3, 3, 3, 3], [0, 3, 1, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 2], [0, 2, 0, 0], [0, 0, 3, 0], [1, 0, 0, 0], [0, 3, 3, 0], [3, 0, 0, 0], [0, 3, 3, 3], [0, 2, 1, 0], [0, 2, 3, 3], [3, 3, 3, 0], [1, 0, 0, 0], [0, 2, 0, 0], [2, 2, 2, 3], [0, 2, 3, 0], [2, 2, 3, 3], [0, 0, 0, 1], [0, 0, 0, 0], [0, 1, 0, 0], [3, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 1], [3, 3, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 0, 0, 3], [0, 3, 3, 0], [3, 0, 3, 3], [2, 0, 0, 3], [0, 0, 2, 0], [0, 0, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 3, 0, 0], [0, 3, 0, 3], [0, 0, 1, 1], [0, 0, 0, 1], [0, 0, 3, 0], [0, 0, 0, 1], [0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [3, 0, 0, 0], [1, 2, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0], [0, 3, 3, 0], [3, 3, 0, 0], [0, 2, 0, 0], [0, 0, 0, 2], [0, 3, 0, 0], [3, 2, 0, 0], [0, 0, 0, 2], [0, 0, 2, 0], [3, 3, 3, 1], [3, 3, 1, 0], [0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 2], [1, 0, 0, 0], [1, 0, 0, 0], [0, 1, 2, 0], [3, 2, 3, 0], [0, 0, 0, 2], [0, 2, 3, 2], [0, 1, 0, 0], [3, 2, 1, 0], [3, 2, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 3, 0, 3], [0, 3, 0, 0], [0, 2, 0, 0], [1, 0, 1, 0], [2, 0, 0, 0], [0, 2, 0, 0], [0, 1, 1, 0], [2, 3, 3, 3], [0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 2], [3, 3, 0, 0], [1, 3, 1, 3], [3, 0, 0, 0], [0, 0, 0, 1], [0, 0, 2, 2], [0, 0, 0, 0], [0, 3, 3, 0], [0, 0, 0, 2], [3, 1, 0, 3], [3, 1, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [3, 0, 3, 1], [1, 3, 1, 3], [0, 3, 0, 0], [0, 3, 1, 0], [1, 2, 2, 0], [0, 0, 0, 0], [0, 3, 0, 0], [0, 0, 1, 0], [1, 3, 1, 0], [0, 0, 1, 0], [0, 3, 0, 3], [1, 3, 3, 1], [0, 0, 0, 0], [0, 0, 2, 0], [3, 3, 1, 0], [1, 0, 0, 0], [0, 2, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0], [0, 3, 3, 3], [0, 0, 0, 0], [2, 0, 0, 0], [0, 3, 0, 0], [0, 0, 0, 0], [0, 0, 1, 0], [3, 3, 3, 0], [0, 0, 0, 1], [0, 0, 1, 2], [0, 0, 3, 3], [0, 0, 0, 0], [0, 1, 1, 0], [0, 0, 0, 3], [3, 3, 0, 0], [0, 0, 0, 0], [3, 1, 3, 3], [0, 3, 0, 1], [1, 0, 0, 1], [3, 2, 0, 0], [3, 1, 1, 0], [0, 0, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 1, 1, 0], [0, 0, 0, 2], [0, 0, 0, 0], [3, 0, 3, 0], [0, 0, 0, 0], [0, 0, 1, 1], [3, 2, 0, 3], [1, 3, 0, 1], [0, 2, 1, 0], [0, 3, 0, 0], [2, 2, 2, 0], [0, 0, 0, 0], [0, 0, 3, 0], [0, 0, 0, 0], [2, 0, 0, 3], [3, 3, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0], [0, 0, 1, 1], [3, 0, 0, 0], [1, 0, 0, 0], [1, 2, 2, 3], [3, 1, 3, 0], [0, 0, 1, 0], [0, 0, 0, 2], [0, 0, 0, 1], [2, 0, 0, 0], [3, 3, 3, 0], [0, 1, 0, 0], [3, 0, 0, 0], [0, 3, 0, 0], [0, 1, 3, 0], [0, 3, 0, 1], [1, 0, 0, 1], [0, 1, 3, 0], [0, 2, 0, 0], [2, 2, 0, 2], [3, 0, 0, 0], [0, 0, 0, 2], [1, 2, 1, 0], [0, 1, 0, 0], [0, 1, 1, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [0, 1, 1, 0], [2, 2, 0, 0], [0, 0, 0, 0], [0, 2, 2, 0], [0, 0, 1, 1], [3, 0, 0, 0], [0, 0, 0, 0], [3, 0, 3, 0], [0, 3, 3, 3], [0, 0, 0, 0], [3, 3, 1, 0], [0, 0, 0, 0], [0, 0, 1, 0], [0, 3, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 3, 0], [1, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [3, 2, 0, 0], [0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 2, 0], [0, 1, 0, 0], [0, 3, 3, 0], [0, 1, 0, 0], [3, 2, 0, 0], [0, 0, 0, 0], [0, 0, 3, 2], [0, 1, 1, 0], [0, 0, 0, 0], [0, 0, 1, 0], [3, 0, 3, 0], [3, 3, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0], [3, 3, 0, 0], [0, 1, 1, 0], [3, 0, 0, 0], [0, 3, 0, 0], [0, 3, 3, 0], [1, 0, 0, 0], [0, 3, 0, 0], [3, 0, 0, 3], [0, 0, 0, 1], [1, 0, 0, 1], [0, 0, 0, 2], [0, 2, 0, 0], [0, 1, 0, 3], [0, 0, 0, 0], [3, 3, 0, 0], [0, 3, 3, 2], [0, 0, 0, 0], [1, 0, 0, 2], [0, 3, 0, 3], [0, 1, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0], [0, 3, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0, 0, 2, 0], [0, 0, 1, 0], [0, 0, 3, 0], [0, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0], [0, 2, 0, 0], [0, 3, 0, 0], [0, 3, 0, 0], [0, 2, 0, 0], [1, 3, 0, 0], [0, 0, 3, 0], [0, 0, 0, 1], [0, 2, 3, 0], [0, 0, 1, 1], [3, 2, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [3, 3, 3, 0], [0, 0, 0, 1], [0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 3, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 1, 0, 0], [3, 3, 3, 0], [1, 0, 0, 0]]\n",
            "100% 477/477 [00:11<00:00, 40.28it/s]\n",
            "[{'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'o', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'x', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'x', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'n'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'p', 'scene': 'n', 'sound': 'n'}, {'character': 'n', 'content': 'p', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'o'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'p', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}, {'character': 'n', 'content': 'n', 'scene': 'p', 'sound': 'x'}, {'character': 'p', 'content': 'n', 'scene': 'n', 'sound': 'x'}]\n",
            "/content/drive/MyDrive/ABSA-MLQ/eval.py:140: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  y_pred=y_pred.applymap(lambda x: x.lower() if pd.notnull(x) else x)\n",
            "/content/drive/MyDrive/ABSA-MLQ/eval.py:144: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  y_test=y_test.applymap(lambda x: x.lower() if pd.notnull(x) else x)\n",
            "/content/drive/MyDrive/ABSA-MLQ/eval.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_test= y_test.fillna('not_exist').replace(aspect_map).values.tolist()\n",
            "/content/drive/MyDrive/ABSA-MLQ/eval.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_pred= y_pred.fillna('not_exist').replace(aspect_map).values.tolist()\n",
            "## Sentiment Classification Evaluate ##\n",
            "\n",
            "        precision    recall  f1-score   support\n",
            "\n",
            "        None     0.9200    0.9500    0.9349       146\n",
            "    negative     0.1000    0.0200    0.0323       194\n",
            "     neutral     0.1800    0.3200    0.2273       330\n",
            "    positive     0.8500    0.8200    0.8346      1238\n",
            "\n",
            "    accuracy                         0.8341      1908\n",
            "   macro avg     0.5875    0.5525    0.5073      1908\n",
            "weighted avg     0.8183    0.8341    0.8234      1908\n",
            "\n",
            "\n",
            "\n",
            "Detailed report (output_dict):\n",
            "\n",
            "## Aspect Detection Evaluate ##\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        None     0.8500    0.9200    0.8842       1238\n",
            "   character     0.8800    0.9500    0.9143       171\n",
            "     content     0.8100    0.8700    0.8395       204\n",
            "       scene     0.8700    0.9600    0.9130       168\n",
            "       sound     0.9000    0.9800    0.9394       127\n",
            "\n",
            "    accuracy                         0.8687      1908\n",
            "   macro avg     0.8620    0.9440    0.8941      1908\n",
            "weighted avg     0.8742    0.8687    0.8671      1908\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}